Processing Layer: "conv2d" (Conv2D)
InputSize = 3072
KernelSize = 1728
BiasSize = 64
Conv2D Output Size = 65536
First Channel output values "conv2d" layer:
0 0.239747 0 0 0 0.17633 0.336477 0 0 0.0409458 0.166951 0.0945611 0.0691799 0 0.0324578 0 0.0750437 0.0373321 0 0 0 0 0 0 0 0.020092 0 0 0.155553 0 0 0 0.193263 
0 0.104212 0 0.0595268 0 0 0 0 0.0603049 0 0 0 0.212749 0 0.121631 0.0913641 0 0.277315 0.0687967 0.164273 0 0 0 0 0 0.0476848 0.0224431 0.085008 0.338842 0.0859596 0.0516327 0 
0.287197 0 0.0522472 0 0.0532416 0.340036 0 0.0331537 0 0.199253 0.103984 0 0 0.0841258 0.0323352 0 0.0118682 0 0.0837319 0.0679164 0 0 0 0 0.0183944 0.0752667 0.0406075 0 0 0 0.0244604 0.0520727 
0 0.0671495 0 
65536
=======================================================================
Processing Layer: "batch_normalization" (BatchNormalization)
Input size: 65536
Gamma size: 64
Beta size: 64
Moving Mean size: 64
Moving Variance size: 64
65536
65536
BatchNorm Output Size = 65536
First Channel output values "batch_normalization" layer:
-0.15954 4.08027 -0.0743323 -0.75255 -0.223816 5.44535 6.0069 -0.0746323 -0.435777 1.19629 1.38239 1.82369 2.0873 -0.129793 0.774351 -0.688277 1.19728 0.815962 0.0526698 -0.39792 -0.339949 -0.31557 -0.0149697 -0.366907 -0.359704 0.0371025 -0.386477 -0.338023 3.83846 -0.283426 -0.234857 -0.255992 2.82997 
-0.333007 2.05539 -0.269531 1.2371 -0.074966 -0.521947 -0.428835 -0.223226 2.04799 -0.269762 -0.254183 -0.316745 3.78517 -2.22772 2.9453 2.0945 -0.105515 3.50275 2.33643 3.74702 -0.129153 0.14921 -0.0644888 -0.00345478 0.011752 -1.02301 0.695234 2.23974 6.36677 2.64543 1.31839 -0.15954
4.98803 -0.0743323 0.495429 -0.223816 1.59238 6.07455 -0.0746323 0.461578 -0.188032 1.97856 2.07718 -0.0495952 -0.129793 2.19478 0.302045 -0.681921 0.0994748 0.0526698 1.2711 1.58235 -0.31557 -0.0149697 -0.366907 -0.359704 0.00953909 0.778591 0.849915 -0.377406 -0.283426 -0.234857 0.637031 0.289632
-0.333007 1.1891 -0.269531
=======================================================================
Processing Layer: "max_pooling2d" (MaxPooling2D)
InputSize = 65536
MaxPool Output Size = 16384
First Channel output values "max_pooling2d" layer:
-0.15954 4.98803 -0.0743323 0.495429 -0.223816 5.44535 6.07455 -0.0746323 0.618645 1.19629 2.59417 2.07718 2.0873 -0.129793 2.19478 0.302045 3.40122 2.7528 0.0526698 1.2711 1.68464 0.881766 -0.0149697 -0.366907 0.243669 0.943138 0.778591 0.849915 3.83846 -0.283426 -0.234857 0.637031 2.82997
0.390281 2.05539 0.104486 1.2371 -0.074966 0.879633 3.81902 -0.145182 2.04799 1.97734 0.726723 -0.225391 5.77387 0.345999 2.9453 2.87933 -0.105515 4.3952 2.33643 5.80055 -0.129153 0.14921 -0.0644888 -0.00345478 0.011752 0.464686 0.695234 2.23974 6.36677 2.64543 1.31839 -0.15954
4.98803 -0.0743323 0.495429 -0.223816 1.59238 6.07455 -0.0746323 0.618645 -0.188032 1.97856 2.07718 -0.0495952 -0.129793 2.19478 0.302045 -0.188027 0.0994748 0.0526698 1.2711 1.58235 -0.130712 -0.0149697 -0.366907 0.243669 0.00953909 0.778591 0.849915 -0.377406 -0.283426 -0.234857 0.637031 0.753448 
0.390281 1.1891 0.104486
=======================================================================
Processing Layer: "conv2d_1" (Conv2D)
InputSize = 16384
KernelSize = 409600
BiasSize = 256
Conv2D Output Size = 65536
First Channel output values "conv2d_1" layer:
0.372548 0 0 0 0.566203 0.0152251 0 0 0 0.678988 0 0 0.144194 0 0 0 0 0.632461 0 0 0.399212 0 0 0.232439 0 0.731518 0 0 0 0 0 0 0.00522119
0.157028 0 0.0330071 0 0.679937 0 0 0 0.632995 0 0.0838079 0.186275 1.2216 0 0 0 1.13421 0 1.26141 0 0 0 0 0 0.826302 0 0 0 0.387687 0 0 0
0 0 0 0 0.676301 0 0 1.0465 0 0 0 0 0 0.0847324 0 0 0 0.0404761 0.361493 0 0 0.162661 0 0 0 0 0 0 0.856503 0 0 0
0 0.100723 0.745454
65536
=======================================================================
Processing Layer: "batch_normalization_1" (BatchNormalization)
Input size: 65536
Gamma size: 256
Beta size: 256
Moving Mean size: 256
Moving Variance size: 256
65536
65536
BatchNorm Output Size = 65536
First Channel output values "batch_normalization_1" layer:
1.41926 -0.361212 -0.339052 -0.382925 0.493284 -0.137628 -0.361824 -0.311267 -0.28339 0.751727 -0.447958 -0.426206 -0.224302 -0.43237 -0.395511 -0.431685 -0.345605 1.89322 -0.370304 -0.307523 -0.381375 -0.630024 -0.295971 0.272491 -0.434627 0.804266 -0.231885 -0.446024 -0.274742 -0.264029 -0.359926 -0.417142 -0.506254
-0.354825 -0.710494 -0.463528 -0.450499 0.92643 -0.595207 -0.293096 -0.363768 0.423663 -0.63001 -0.0789662 1.04235 2.91205 -0.339943 -0.491465 -0.338663 0.987388 -0.376779
 2.29285 -0.329963 -0.319139 -0.656904 -0.433276 -0.348419 1.96785 -0.62255 -0.42302 -0.381357 1.05514 -0.464785 -0.312326 -0.62552 
-0.318205 -0.578534 -0.457438 -0.300822 1.92789 -0.337757 -0.264353 3.31582 -0.254914 -0.44586 -0.307523 -0.338352 -0.334182 -0.0497789 -0.267901 -0.339128 -0.404567 -0.304479 0.301792 -0.393397 -0.371585 0.0670095 -0.558587 -0.33937 -0.384673 -0.4119 -0.572371 -0.384504 0.990016 -0.465929 -0.38399 -0.304143
-0.41334 0.0113259 2.25907
=======================================================================
Processing Layer: "max_pooling2d_1" (MaxPooling2D)
InputSize = 65536
MaxPool Output Size = 16384
First Channel output values "max_pooling2d_1" layer:
3.22504 -0.361212 -0.339052 -0.382925 0.493284 -0.137628 4.7839 3.42669 -0.28339 0.751727 -0.447958 -0.426206 0.0860965 2.30974 0.316771 -0.431685 -0.345605 1.89322 -0.370304 -0.307523 0.567257 1.0193 -0.295971 3.59824 -0.434627 0.804266 1.6573 -0.446024 -0.132051 -0.264029 -0.359926 -0.417142 -0.506254
0.10358 0.112794 -0.463528 -0.450499 0.92643 -0.595207 -0.293096 -0.363768 0.423663 -0.63001 4.1926 1.04235 5.24343 -0.339943 2.72171 -0.338663 0.987388 -0.376779 2.29285 -0.329963 -0.319139 -0.00503617 -0.433276 -0.348419 1.97048 -0.385579 -0.42302 -0.381357 1.05514 0.85922 2.07655 -0.62552
-0.318205 1.21059 -0.24578 -0.300822 1.92789 -0.337757 1.62082 4.94829 -0.254914 3.18975 -0.307523 0.963244 -0.334182 2.60625 -0.267901 -0.339128 0.227609 -0.304479 1.27279 1.78829 -0.296902 3.77221 -0.172869 -0.33937 -0.224063 0.54572 -0.572371 0.68612 1.79131 -0.465929 -0.38399 1.8048
-0.36749 0.0113259 2.25907
=======================================================================
Processing Layer: "conv2d_2" (Conv2D)
InputSize = 16384
KernelSize = 1179648
BiasSize = 512
Conv2D Output Size = 32768
First Channel output values "conv2d_2" layer:
0 0 0 0 0.247816 0 1.52728 0.0565175 0 0.516973 0 0 1.67736 0 0 0.732913 0 0 0 0 0 0.203199 0 0.882815 0.862644 0 0 0.431133 0 0.468152 0.197878 0 0.36727
0 2.88219 0 0 0.227597 0 0.37969 0 1.81117 1.00634 0 0 0 0 0 0 0 0 0 0 0.963224 0 0.256388 0.762604 0 0 0 0 0 0 1.05318 0
0.595539 0.746711 0.742254 0.410828 0 1.25483 0 0 0.802569 0 0 0 0 0 0 0.51511 0 0 1.29976 0 1.67074 2.26043 0 0 0 0.662317 2.26041 0 0 0.104015 0 0
0 0 0
32768
=======================================================================
Processing Layer: "batch_normalization_2" (BatchNormalization)
Input size: 32768
Gamma size: 512
Beta size: 512
Moving Mean size: 512
Moving Variance size: 512
32768
32768
BatchNorm Output Size = 32768
First Channel output values "batch_normalization_2" layer:
0.455198 0.178711 0.235483 0.29777 1.12538 0.19707 1.20564 0.372788 0.168766 0.114933 0.499372 1.99589 0.475758 0.848889 0.207933 1.37298 0.388465 0.240837 0.941836 0.166501 0.135506 0.272517 0.184559 0.348679 0.989246 0.863125 0.294373 0.700831 0.208882 1.64141 0.133715 0.143543 0.709149 
1.84758 1.10093 0.376046 1.42522 1.8069 0.291259 0.289154 0.719508 1.35795 0.30502 1.14458 1.47325 0.237799 0.29176 0.194591 0.116224 0.68132 0.23208 0.159534 0.204536 0.136936 0.171183 0.425576 0.201288 0.825441 0.35537 0.199064 0.221356 0.292942 0.52183 0.450516 0.285597
0.972721 0.920055 0.661791 0.427545 0.446654 0.440813 0.17696 0.490449 2.64304 0.197547 0.716072 3.1724 0.295597 0.243312 0.623932 2.36594 0.214573 0.197169 1.90163 0.481744 0.916626 1.16332 0.187176 0.245609 0.202706 0.873052 1.73255 0.194088 0.407456 1.11541 1.515 0.237508 
0.204637 0.370849 0.875429
=======================================================================
Processing Layer: "max_pooling2d_2" (MaxPooling2D)
InputSize = 32768
MaxPool Output Size = 8192
First Channel output values "max_pooling2d_2" layer:
0.455198 0.178711 0.235483 0.29777 1.13425 0.19707 1.21042 0.372788 0.168766 0.123133 0.499372 1.99589 0.533256 0.848889 0.207933 1.37298 0.388465 0.240837 0.941836 0.166501 0.135506 0.272517 0.184559 0.379423 0.989246 0.863125 0.294373 0.700831 0.208882 1.65574 0.138103 0.143543 0.719993
1.84758 1.12378 0.376046 1.42522 1.81291 0.291259 0.308426 0.719508 1.37187 0.30502 1.14458 1.47325 0.237799 0.29176 0.194591 0.116224 0.68132 0.23208 0.159534 0.204536 0.136936 0.171183 0.425576 0.23737 0.825441 0.35537 0.199064 0.221356 0.292942 0.52183 0.450516 0.285597
0.972721 0.955401 0.693484 0.437913 0.446654 0.514691 0.17696 0.490449 2.66327 0.197547 0.716072 3.1724 0.295597 0.243312 0.623932 2.37732 0.214573 0.197169 1.94749 0.481744 0.916626 1.20791 0.187176 0.245609 0.202706 0.892998 1.76232 0.194088 0.407456 1.11933 1.515 0.237508
0.204637 0.370849 0.875429
=======================================================================
Processing Layer: "dense" (Dense)
Dense Output Size = 512
First Channel output values "dense" layer:
0 0 0 0 0 0 0 0 0 0
=======================================================================
Processing Layer: "dense_1" (Dense)
Dense Output Size = 10
First Channel output values "dense_1" layer:
0.168837 0.0711195 0.151665 0.146998 0.0659216 0.0977819 0.0834349 0.0865089 0.0534463 0.0742879
=======================================================================
Max value: 0.168837 at index 0
Predicted Class: airplane
Processing completed successfully!

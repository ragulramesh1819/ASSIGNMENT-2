E:\Assignment-2-C++\Project_Root\build\Debug>cd..

E:\Assignment-2-C++\Project_Root\build>cmake ..       
-- Selecting Windows SDK version 10.0.22621.0 to target Windows 10.0.26100.
-- Configuring done (0.0s)
-- Generating done (0.0s)
-- Build files have been written to: E:/Assignment-2-C++/Project_Root

E:\Assignment-2-C++\Project_Root\build>cmake --build .
MSBuild version 17.12.12+1cce77968 for .NET Framework

  main.cpp
  Conv2DApp.vcxproj -> E:\Assignment-2-C++\Project_Root\build\Debug\Conv2DApp.exe

E:\Assignment-2-C++\Project_Root\build>cd Debug

E:\Assignment-2-C++\Project_Root\build\Debug>.\Conv2DApp.exe
Processing layer: "conv2d" ("Conv2D")
Performing Conv2D operation.

==============================="conv2d"========================================
0.0228943 0.0690305 0.0998776 0 0.0430121 0.387061 0.162102 0.00889452 0 0 0.26021 0.161234 0 0.00665376 0.0169032 0 0 0 0 0.127231 0 0 0.228474 0.0146484 0 0.0138155 0 0.00912028 0.150913 0 0.17564 0 0 0 0 0.349068 0.100559 0 0 0 0.0897804 0.0336033 0.0973593 0 0 0 0.023082 0.183724 0.140013 0.0289553 0.0382434 0 0 0.254942 0 0 0 0 0.103202 0 0.0962845 0.265033 0.179505 0

Processing layer: "batch_normalization" ("BatchNormalization")
Performing BatchNormalization operation.

==============================="batch_normalization"========================================
6.96855 1.12177 14.8023 -1.23001 2.43247 44.6323 3.41962 1.87595 -0.857852 -0.509414 4.28457 6.48291 -0.232299 1.17415 0.811755 -1.46247 -1.26153 -0.481977 -0.0171723 2.81707 -0.602077 -0.65919 37.0982 -0.0855368 -0.661722 -0.0847009 -0.467434 -0.166396 6.69875 -0.716903 9.87125 -0.787922 -0.858493 -0.915079 -0.627509 11.3147 4.14201 -0.292719 -1.03532 -0.586543 5.57837 3.29446 5.26878 -0.641614 -0.595965 -0.319475 -2.57343 9.10105 5.61543 1.70563 -0.314152 -0.095032 -0.518988 11.677 0.128286 -0.22307 -0.118962 -0.16524 -0.0758876 -0.201462 5.84486 6.81803 22.3142 -0.519668

Processing layer: "max_pooling2d" ("MaxPooling2D")
Performing MaxPooling2D operation.

==============================="max_pooling2d"========================================
25.3124 2.08686 14.8023 3.36949 10.4007 80.0414 11.1012 9.88042 -0.857852 7.48233 12.7126 6.48291 1.1639 31.7835 0.811755 -1.46247 -1.26153 1.64341 -0.0171723 7.37634 15.3062 -0.65919 48.6787 -0.0855368 12.8565 3.2555 -0.467434 13.3563 6.69875 -0.716903 19.8001 -0.787922 -0.858493 -0.915079 -0.627509 25.9003 5.14314 -0.292719 6.0342 1.78458 5.57837 24.8532 7.85437 26.5069 9.52541 2.18831 -1.84032 14.2156 8.25121 1.70563 -0.314152 6.05148 -0.518988 11.677 0.128286 -0.22307 -0.118962 17.7525 13.6006 0.999524 12.371 10.0517 25.0722 -0.519668
Skipping unsupported layer: "dropout" (Dropout)
Processing layer: "conv2d_1" ("Conv2D")
Performing Conv2D operation.

==============================="conv2d_1"========================================
9.20239 0 0 7.79632 0 0 0 0 0 0 0 0 0.0342995 6.72328 5.93133 0 4.9243 0 0 1.24729 0 0 0 0 0 0 0 5.8142 3.32809 0 0 2.79141 0.572064 0 4.49383 0 0 8.53897 0 0 2.97959 0 0.493918 2.43396 1.22359 0 0 0 6.93334 0 7.09867 0.777617 0 2.72921 0 1.26391 10.8385 0 0.683009 0 3.97642 1.26078 0 0 0 0 0 0 0 0 0.828552 0 0 0 0 3.54705 5.42759 0 0 0 0 0 0 0 0 0 0 0 0.654851 1.21806 0 0.819071 0 0 0 2.87887 0 6.89658 4.05271 0 0 0.321293 0 0 0 0 2.30255 0 0 0 0 6.81336 3.7564 8.27336 13.5193 6.95602 0 0.827837 0.767381 6.69294 0 0 0 1.64515 0 7.1208 0 0 0.938684 2.60476 0 0 4.09447 2.4677 0 0 1.55657 0 0 0 0 0 8.20148 0 4.31526 5.08831 0 0 0.577612 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 7.96183 7.12683 0 0 0.0326654 0 0 0 5.77263 0 0 0 0 1.34149 0 0 0 0 2.52223 0 0 0 0 0 0 0 0 0 4.0739 3.30086 0 0 0 0 0 4.37462 0.362988 0 0 0 0 0 0.798541 0 0 0 1.75995 0 0 0 1.58828 0 0 0 0 0 0 10.6379 0 0 6.25433 0 0 0 0 0 0 3.90356 0 0 1.67104 0 0 0 0 0.199409 0 0 0 0 0.303222 0 0 0 1.05596 0 

Processing layer: "batch_normalization_1" ("BatchNormalization")
Performing BatchNormalization operation. 

==============================="batch_normalization_1"========================================
43.488 -0.363031 -0.342138 18.8976 -0.54358 -0.232202 -0.364121 -0.313004 -0.286365 -0.552755 -0.449015 -0.428273 -0.462808 22.4645 19.0465 -0.433791 12.3374 -0.379785 -0.373474 3.50362 -0.875734 -0.631198 -0.299819 -0.40504 -0.435901 -0.546333 -0.235412 16.369 15.3561 -0.268146 -0.36186 9.37063 1.0944 -0.649691 5.29869 -0.545622 -0.451798 18.0094 -0.595954 -0.297148 8.71378 -0.670364 0.242038 7.61196 8.42227 -0.515935 -0.341727 -0.492589 26.5869 -0.793673 27.7734 1.25402 -0.33192 8.17863 -0.657938 2.15361 34.6527 -0.452402 0.410798 -0.424238 12.0651 4.36761 -0.466648 -0.315101 -0.626516 -0.320836 -0.57963 -0.459934 -0.30391 -0.405105 3.83689 -0.268911 -0.332822 -0.257549 -0.447564 16.1794 17.0784 -0.337395 -0.359323 -0.27043 -0.341685 -0.406644 -0.404277 -0.537206 -0.395137 -0.374487 -0.431835 -0.559711 2.62015 4.34813 -0.413949 0.909899 -0.386331 -0.660829 -0.46679 8.96159 -0.306877 18.7891 17.8368 -0.451414 -0.374388 0.102312 -0.432291 -0.253433 -0.489121 -0.456381 6.61934 -0.353554 -0.550084 -0.376557 -0.520266 14.2791 12.9203 22.044 38.7409 28.472 -0.404357 1.08991 2.37083 27.4622 -0.577181 -0.405822 -0.282834 3.77021 -0.403996 53.9401 -0.373898 -0.337048 3.2396 6.90775 -0.430618 -0.527243 5.74623 8.5389 -0.544594 -0.306401 5.10497 -0.428567 -0.822404 -0.541637 -0.658654 -0.329257 18.885 -0.556605 8.95622 17.6803 -0.363051 -0.415364 1.97125 -0.382764 -0.281101 -0.564759 -0.362857 -0.347204 -0.367191 -0.47274 -0.572523 -0.49268 -0.743701 -0.402656 -0.445799 -0.6315 -0.403821 -0.405686 -0.39036 -0.303414 -0.495429 -0.668099 -0.491923 -0.442873 11.5141 17.3659 -0.453817 -0.360989 0.00315265 -0.250397 -0.732372 -0.365085 13.287 -0.551589 -0.495751 -0.59383 -0.372355 3.23073 -0.673279 -0.626881 -0.346699 -0.374474 7.88745 -0.297953 -0.410941 -0.414842 -0.349492 -0.3849 -0.292296 -0.560677 -0.585241 -0.603758 16.4713 4.05559 -0.379802 -0.471956 -0.615709 -0.804236 -0.402039 12.4996 0.435204 -0.370721 -0.706547 -0.466059 -0.602422 -0.654465 0.632584 -0.458848 -0.26099 -0.511909 5.66562 -0.371268 -0.453397 -0.449757 4.53039 -0.512724 -0.31984 -0.43391 -0.493896 -0.491739 -0.371524 55.1276 -0.340593 -0.456324 9.9878 -0.364651 -0.430605 -0.3472 -0.563255 -0.493174 -0.727329 24.6927 -0.628778 -0.303519 1.93128 -0.406215 -0.403672 -0.646066 -0.67043 -0.384914 -0.304867 -0.660837 -0.343707 -0.406698 0.867972 -0.376415 -0.459329 -0.24412 7.02563 -0.348542

Processing layer: "max_pooling2d_1" ("MaxPooling2D")
Performing MaxPooling2D operation.

==============================="max_pooling2d_1"========================================
121.199 -0.363031 -0.342138 18.8976 10.143 11.5379 8.71445 -0.313004 -0.286365 -0.552755 -0.449015 -0.428273 -0.462808 26.4898 22.0527 10.5056 12.3374 -0.211137 -0.373474 3.50362 -0.875734 -0.631198 -0.299819 -0.40504 -0.435901 5.3341 -0.235412 16.369 101.302 18.4382 7.29382 21.7588 10.0412 -0.649691 5.29869 -0.545622 2.74121 18.0094 -0.595954 -0.297148 15.619 -0.670364 0.242038 29.8866 53.9571 3.53712 -0.341727 -0.492589 44.6995 -0.793673 27.7734 1.25402 -0.33192 17.0441 -0.657938 2.15361 79.2523 63.6237 6.55605 6.03588 32.1347 20.1465 -0.466648 -0.315101 -0.626516 -0.320836 -0.57963 0.223907 -0.30391 -0.405105 16.7446 22.097 10.7684 -0.257549 -0.447564 16.1794 26.2659 -0.337395 3.6276 -0.27043 -0.341685 -0.406644 -0.404277 -0.537206 -0.395137 30.9619 -0.431835 14.7505 3.34748 10.3651 -0.413949 0.909899 -0.386331 -0.660829 -0.46679 20.3842 5.71654 47.0324 43.3041 -0.451414 -0.374388 10.0859 -0.432291 -0.253433 -0.489121 -0.456381 6.61934 -0.353554 -0.550084 -0.376557 -0.520266 19.07 20.2225 48.6153 94.9578 28.472 -0.404357 20.5355 3.75998 27.4622 -0.577181 -0.405822 3.51709 14.2229 -0.403996 74.905 -0.373898 12.509 3.2396 6.90775 -0.430618 -0.527243 5.74623 8.5389 -0.544594 0.964095 5.10497 -0.428567 -0.822404 -0.541637 4.56594 1.56476 33.2334 -0.556605 8.95622 30.4252 -0.363051 -0.415364 38.5154 -0.382764 -0.281101 1.98336 -0.362857 -0.347204 -0.367191 -0.47274 5.61079 -0.49268 -0.743701 -0.402656 -0.445799 9.46772 -0.403821 4.97507 -0.39036 -0.303414 -0.495429 6.14577 8.72193 12.0336 19.3835 26.8012 -0.453817 -0.360989 19.1483 -0.250397 -0.732372 -0.365085 13.287 -0.551589 -0.495751 5.71135 -0.372355 6.96674 -0.673279 -0.626881 -0.346699 -0.374474 25.84 11.2722 10.8897 -0.414842 -0.349492 -0.3849 -0.292296 -0.560677 -0.585241 4.46361 31.1623 14.666 14.0246 -0.471956 -0.588421 -0.804236 -0.402039 70.0969 0.435204 -0.370721 -0.706547 -0.466059 -0.602422 -0.654465 0.632584 -0.458848 -0.26099 -0.511909 5.66562 -0.371268 -0.453397 -0.449757 6.97747 -0.512724 -0.31984 -0.43391 -0.493896 -0.491739 11.7408 111.081 -0.340593 -0.456324 9.9878 -0.364651 -0.430605 38.6902 -0.563255 -0.493174 -0.727329 24.6927 -0.628778 -0.303519 6.94586 -0.406215 -0.403672 -0.646066 -0.67043 -0.384914 -0.304867 3.70991 -0.343707 -0.406698 5.95717 -0.376415 -0.459329 -0.24412 24.6364 25.0948
Skipping unsupported layer: "dropout_1" (Dropout)
Processing layer: "conv2d_2" ("Conv2D")
Performing Conv2D operation.

==============================="conv2d_2"========================================
0 0 0 0 0.804479 0 0.589139 0 0 0 0 0 0 24.3087 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3.4594 0 0 0 0 0 0 0 0 0 0 10.4079 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2.19699 0 0 0 0 0 0 0 0 0 0 0 0 2.45329 0 7.57669 3.53286 0 0 0 0 0 0 0 12.6075 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1.49946 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 7.16705 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 7.58943 0 0 0 0 0 0 0 0 0 0 0 3.81475 0 0 0 0 0 0 0 0 0 0 9.28173 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 7.26653 0 0 0 0 0 0 0 0 0.305694 0 0 0.449024 0 11.7762 0 0 0 0 3.19319 0 0 0 0 0 0 0 0 0 3.01446 11.537 0 0 0 0 0 0 0 0 0 0 0 16.3971 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0.0226652 0 21.2574 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1.98563 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 7.01601 6.98144 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 7.43582 0 0 0 0 0 2.01135 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 10.0164 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 18.549 2.48189 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0

Processing layer: "batch_normalization_2" ("BatchNormalization")
Performing BatchNormalization operation.

==============================="batch_normalization_2"========================================
-0.426984 -0.224431 -0.296001 -0.313195 -0.217639 -0.261716 -0.357026 -0.369954 -0.235316 -0.219436 -0.463205 -0.789985 -0.417303 13.0562 -0.260356 -0.685613 -0.377908 -0.303342 -0.546215 -0.23213 -0.219641 -0.331339 -0.239468 -0.370991 -0.564132 -0.546727 -0.323423 -0.567017 -0.273372 -0.694835 -0.231567 -0.20374 -0.484082 -0.787655 -0.62695 -0.383001 -0.619998 -0.791724 -0.332079 -0.333474 -0.496353 -0.676933 -0.331809 -0.626274 -0.631328 -0.292428 -0.305988 -0.273769 -0.181263 -0.484846 -0.290889 -0.195827 -0.244693 -0.278199 -0.232824 -0.398472 -0.30494 -0.517425 -0.341895 -0.256884 4.73701 -0.343615 -0.403354 -0.403657 -0.321626 -0.586414 -0.613358 -0.485266 -0.371762 -0.40327 -0.440216 15.6945 -0.392733 -0.970638 -0.294482 -0.478582 -1.09905 -0.319917 -0.302174 -0.451151 -0.93388 -0.263008 -0.256968 -0.835068 -0.425018 -0.526838 -0.627175 -0.257102 -0.30268 -0.250128 -0.528073 -0.769665 -0.258536 -0.410272 -0.654633 -0.688926 -0.295726 -0.268097 -0.381107 -0.528978 -0.488484 -0.290826 -0.260886 -0.298319 -0.198277 -0.434158 -0.342737 -0.754287 -0.40513 -0.242651 -0.475386 -0.310139 -0.363782 0.370386 -0.31377 -0.322698 -0.300004 -0.314939 -0.651164 -0.206997 -0.249655 -0.816015 -1.05338 -0.423311 -0.815691 -0.226609 1.08861 -0.313318 2.73702 1.07466 -0.753043 -0.412162 -0.422868 -0.34775 -0.283044 -0.282042 -0.21301 12.8859 -0.481304 -0.340753 -0.431528 -0.544155 -0.31415 -0.238514 -0.312488 -0.346193 -0.286823 -0.33043 -0.748525 -0.98014 -0.492407 -1.03573 -0.254168 -0.340432 -0.600568 -0.603044 -0.6188 -0.211889 -0.20694 -0.280187 -0.286753 0.886182 -0.272744 -0.456996 -0.270212 -0.319115 -0.366019 -0.571789 -0.881176 -0.436178 -0.328373 -0.370755 -0.515897 -0.384355 -0.254783 -0.451551 -0.182983 -0.258531 -0.389639 -0.597224 -0.270165 -0.298529 -0.230833 -0.284804 -0.381157 -0.246954 -0.43759 -0.627351 -0.331432 -0.268705 -1.00098 -0.428459 -0.232146 -0.283323 -0.349301 -0.556578 1.48795 -0.343145 -0.471577 -0.360892 -0.531639 -0.405992 -0.282965 -0.718566 -0.618127 -0.477218 -0.255005 -0.575063 -0.354902 -0.403061 -0.372542 -0.252383 -0.452499 -0.290981 -0.322229 -0.581074 -0.295798 -0.327981 -0.781533 -0.474908 -0.282976 -0.291278 -0.30273 -0.208502 -0.2699 -0.462347 -0.32372 -0.317519 -0.339668 -0.390645 -0.607509 -0.270065 -0.293403 -0.514049 -0.264574 -0.537349 -0.685285 -0.196058 -0.455505 -0.693791 -0.496986 2.76995 -0.332677 -0.540408 -0.324506 -0.453971 -0.298455 -0.370312 -0.936154 -0.290015 -0.358557 -0.539365 -0.680306 1.10093 -0.249763 -0.290863 -0.266336 -0.349138 -0.298595 -0.489985 -0.654553 -0.243636 -0.225235 -0.624876 16.6182 -0.356177 -0.596413 -0.361733 -0.884446 -0.569645 -0.295185 -0.436909 -0.396999 -0.611262 -0.529591 -0.562195 -0.294242 -0.34308 -0.457571 -0.308678 -0.365413 -0.386632 -0.309651 -0.542444 -0.375537 -0.348132 -0.52674 -0.373906 -0.666107 -0.58927 -0.292179 -0.431696 -0.754322 -0.282973 5.60584 -0.31608 -0.633442 -0.298121 -0.348189 -0.613606 -0.310506 -0.294911 -0.847133 -0.119309 -0.244668 -0.252765 0.038256 -0.486064 9.72267 -0.242804 -0.325423 -0.487135 -0.349008 2.00581 -0.400225 -0.34917 -0.379911 -0.962889 -0.513267 -0.266068 -0.294347 -0.484966 -0.57419 0.116756 2.97446 -0.227783 -0.298687 -0.313623 -0.276715 -0.281141 -0.23017 -0.591605 -0.234622 -0.753298 -0.274801 -0.313203 18.6196 -0.29811 -0.801342 -0.398376 -0.340292 -0.595856 -0.376275 -0.37021 -0.338402 -0.313801 -0.529999 -0.18958 -0.623139 -0.89226 -0.422536 -0.646921 -0.404584 -0.206123 -0.259084 27.4438 -0.293789 -0.380867 -0.325496 -0.354847 -0.266476 -0.432378 -0.197443 -0.251653 -0.192712 -0.436306 -0.319694 -0.430338 -0.293941 -0.262096 -0.329738 3.28113 -0.538582 -0.247944 -0.385871 -0.439137 -0.446502 -0.964837 -0.84763 -0.203671 -0.519375 -0.489471 -0.264724 -0.21197 -0.54563 -0.298005 -0.422001 -0.574665 -0.776411 -0.533004 -0.577307 -0.283308 7.01029 7.42031 -0.264659 -0.295722 -0.226472 -0.434978 -1.02008 -0.225773 -0.457274 -0.399072 -0.354866 -0.250147 -0.160309 -0.65328 -0.556304 -0.236181 -0.37219 -0.350434 -0.246801 -0.405495 -0.323135 -0.264304 -0.420731 -0.410847 -0.508994 2.47119 -0.315856 -0.263273 -0.463812 -0.387538 -0.42702 3.00787 -0.827288 -0.492437 -0.380114 -0.257803 -0.259933 -0.32101 -0.332188 -0.267548 -0.322438 -0.624309 -0.249518 -0.251476 -0.414606 -0.378239 -0.71352 -0.463097 -0.902353 -0.714673 -0.562495 -0.25762 -0.367995 -0.898515 -0.341419 -0.287669 -0.365661 -0.258669 -0.291959 -0.196131 -0.195733 12.7991 -0.568356 -0.71575 -0.451675 -0.437698 -0.345318 -0.549556 -0.159802 -0.646111 -0.273865 -0.266827 -0.532079 -0.37078 -0.249721 -0.318635 -0.552428 -0.47667 -0.348315 -0.338709 9.79904 3.46653 -0.825407 -0.334906 -0.375434 -0.655816 -0.371907 -0.266298 -0.552822 -0.390205 -0.397559 -0.698318 -0.303652 -0.345183 -0.343687 -0.571822 -0.427873 -0.775654 -0.639467 -0.282393 -0.636369 -0.323753 -0.40627 -0.279604 -0.483175 -0.256362 -0.438537 -0.458452 -0.213335 -0.459535 -0.75998 -0.801351 -1.06698 -0.243453 -0.360253 -0.82561 -0.397363 -0.264011 -0.930698 -0.327101

Processing layer: "max_pooling2d_2" ("MaxPooling2D")
Performing MaxPooling2D operation.

==============================="max_pooling2d_2"========================================
-0.426984 -0.224431 -0.296001 -0.313195 -0.217639 -0.261716 -0.357026 -0.369954 -0.235316 -0.219436 -0.463205 -0.789985 -0.417303 13.0562 6.05599 -0.685613 -0.377908 -0.303342 -0.546215 -0.23213 -0.219641 -0.331339 -0.239468 -0.370991 -0.564132 -0.546727 -0.323423 -0.567017 -0.273372 -0.694835 -0.231567 -0.20374 -0.484082 -0.787655 -0.62695 0.638296 -0.619998 -0.791724 -0.332079 -0.333474 -0.496353 -0.676933 -0.331809 -0.626274 -0.631328 -0.292428 -0.305988 -0.273769 -0.181263 -0.484846 -0.290889 -0.195827 -0.244693 -0.278199 -0.232824 -0.398472 -0.30494 -0.517425 -0.341895 -0.256884 6.32363 -0.343615 -0.403354 -0.403657 -0.321626 -0.586414 -0.613358 5.04293 -0.371762 -0.40327 -0.440216 15.6945 -0.392733 -0.970638 -0.294482 -0.478582 -1.09905 -0.319917 -0.302174 -0.451151 -0.273432 0.911255 -0.256968 -0.835068 -0.425018 -0.526838 -0.627175 -0.257102 -0.30268 5.84377 -0.528073 -0.769665 -0.258536 -0.410272 6.17521 -0.688926 -0.295726 -0.268097 -0.381107 -0.528978 -0.488484 -0.290826 -0.260886 -0.298319 -0.198277 -0.434158 -0.342737 -0.754287 -0.40513 -0.242651 -0.475386 -0.310139 -0.363782 0.370386 -0.31377 -0.322698 -0.300004 -0.314939 -0.651164 -0.206997 -0.249655 -0.816015 -1.05338 -0.423311 -0.815691 -0.226609 5.7 -0.313318 2.73702 1.32206 -0.753043 -0.412162 -0.422868 -0.34775 -0.283044 -0.282042 -0.21301 17.5535 3.97174 0.919084 -0.431528 -0.544155 -0.31415 26.4705 -0.312488 -0.346193 -0.286823 6.79216 -0.748525 -0.98014 -0.492407 -1.03573 -0.254168 -0.340432 -0.600568 -0.603044 -0.6188 -0.211889 -0.20694 -0.280187 -0.286753 0.886182 -0.272744 -0.456996 -0.270212 3.59901 -0.366019 0.720207 -0.881176 -0.436178 11.1911 -0.370755 -0.515897 -0.384355 -0.254783 -0.451551 3.52629 -0.258531 -0.389639 -0.597224 -0.270165 -0.298529 -0.230833 -0.284804 -0.381157 -0.246954 -0.43759 -0.627351 -0.331432 -0.268705 -1.00098 -0.428459 -0.232146 -0.283323 -0.349301 -0.556578 1.48795 -0.343145 -0.471577 -0.360892 -0.531639 -0.405992 -0.282965 -0.718566 -0.618127 -0.477218 -0.255005 -0.575063 -0.354902 -0.403061 -0.372542 -0.252383 -0.452499 -0.290981 -0.322229 -0.581074 -0.295798 -0.327981 -0.781533 -0.474908 -0.282976 -0.291278 -0.30273 -0.208502 -0.2699 -0.462347 -0.32372 -0.317519 -0.339668 -0.390645 -0.607509 -0.270065 -0.293403 -0.514049 -0.264574 -0.537349 -0.685285 -0.196058 -0.455505 -0.693791 -0.496986 2.76995 -0.332677 -0.540408 -0.324506 -0.453971 -0.298455 -0.370312 -0.936154 -0.290015 -0.358557 -0.539365 -0.680306 1.32915 -0.249763 -0.290863 -0.266336 -0.349138 -0.298595 -0.489985 -0.654553 -0.243636 -0.225235 -0.624876 42.3226 -0.356177 -0.596413 -0.361733 -0.884446 -0.569645 -0.295185 -0.436909 -0.396999 -0.611262 1.38576 -0.562195 -0.294242 -0.34308 -0.457571 -0.308678 -0.365413 -0.386632 -0.309651 -0.542444 -0.375537 -0.348132 -0.52674 -0.373906 -0.666107 -0.58927 -0.292179 -0.431696 -0.754322 -0.282973 5.60584 -0.31608 -0.633442 6.90195 -0.348189 -0.613606 -0.310506 -0.294911 -0.847133 -0.119309 -0.244668 -0.252765 2.70947 -0.486064 9.72267 -0.242804 -0.325423 -0.487135 -0.349008 7.75172 -0.400225 -0.34917 -0.379911 -0.962889 -0.513267 -0.266068 -0.294347 -0.484966 -0.57419 2.87363 2.97446 -0.227783 20.7537 -0.313623 12.0109 -0.281141 5.53571 -0.591605 -0.234622 -0.753298 -0.274801 -0.313203 27.7727 -0.29811 0.607821 -0.398376 -0.340292 -0.595856 -0.376275 -0.37021 -0.338402 -0.313801 -0.529999 -0.18958 -0.623139 -0.89226 -0.422536 -0.646921 -0.404584 9.72703 -0.259084 27.4438 -0.293789 -0.380867 -0.325496 -0.354847 -0.266476 -0.432378 -0.197443 -0.251653 -0.192712 -0.436306 -0.319694 1.79453 -0.293941 -0.262096 -0.329738 3.28113 -0.491839 -0.247944 -0.385871 -0.439137 -0.446502 -0.964837 -0.84763 -0.203671 -0.519375 -0.489471 -0.264724 -0.21197 -0.54563 -0.298005 -0.422001 -0.574665 -0.776411 -0.533004 -0.577307 -0.283308 22.0329 7.42031 -0.264659 -0.295722 -0.226472 4.97705 -1.02008 -0.225773 -0.457274 -0.399072 -0.354866 -0.250147 -0.160309 -0.65328 -0.556304 -0.236181 -0.37219 -0.350434 -0.246801 -0.405495 -0.323135 -0.264304 -0.420731 -0.410847 -0.508994 2.5952 -0.315856 -0.263273 -0.463812 -0.387538 -0.42702 3.00787 -0.827288 -0.492437 -0.380114 -0.257803 -0.259933 -0.32101 -0.332188 -0.267548 -0.322438 -0.624309 -0.249518 -0.251476 -0.414606 -0.378239 -0.71352 -0.463097 -0.902353 -0.714673 -0.562495 -0.25762 4.95862 -0.898515 -0.341419 -0.287669 -0.365661 -0.258669 -0.291959 -0.196131 -0.195733 14.4973 -0.568356 -0.71575 0.673851 -0.437698 -0.345318 -0.549556 -0.159802 -0.646111 -0.273865 -0.266827 -0.532079 -0.37078 -0.249721 -0.318635 -0.552428 -0.47667 -0.348315 -0.338709 11.6678 3.46653 -0.825407 -0.334906 -0.375434 -0.655816 -0.371907 -0.266298 -0.552822 -0.390205 -0.397559 -0.698318 -0.303652 -0.345183 -0.343687 -0.571822 -0.427873 0.0556571 -0.639467 1.14451 -0.636369 -0.323753 -0.40627 -0.279604 -0.483175 -0.256362 -0.438537 -0.458452 -0.213335 0.9607 -0.75998 -0.801351 -1.06698 -0.243453 -0.360253 -0.82561 -0.397363 -0.264011 -0.930698 6.02626    
Skipping unsupported layer: "dropout_2" (Dropout)
Processing layer: "flatten" ("Flatten")
Performing Flatten operation.

==============================="flatten"========================================
-0.426984 -0.224431 -0.296001 -0.313195 -0.217639 -0.261716 -0.357026 -0.369954 -0.235316 -0.219436 -0.463205 -0.789985 -0.417303 13.0562 6.05599 -0.685613 -0.377908 -0.303342 -0.546215 -0.23213 -0.219641 -0.331339 -0.239468 -0.370991 -0.564132 -0.546727 -0.323423 -0.567017 -0.273372 -0.694835 -0.231567 -0.20374 -0.484082 -0.787655 -0.62695 0.638296 -0.619998 -0.791724 -0.332079 -0.333474 -0.496353 -0.676933 -0.331809 -0.626274 -0.631328 -0.292428 -0.305988 -0.273769 -0.181263 -0.484846 -0.290889 -0.195827 -0.244693 -0.278199 -0.232824 -0.398472 -0.30494 -0.517425 -0.341895 -0.256884 6.32363 -0.343615 -0.403354 -0.403657 -0.321626 -0.586414 -0.613358 5.04293 -0.371762 -0.40327 -0.440216 15.6945 -0.392733 -0.970638 -0.294482 -0.478582 -1.09905 -0.319917 -0.302174 -0.451151 -0.273432 0.911255 -0.256968 -0.835068 -0.425018 -0.526838 -0.627175 -0.257102 -0.30268 5.84377 -0.528073 -0.769665 -0.258536 -0.410272 6.17521 -0.688926 -0.295726 -0.268097 -0.381107 -0.528978 -0.488484 -0.290826 -0.260886 -0.298319 -0.198277 -0.434158 -0.342737 -0.754287 -0.40513 -0.242651 -0.475386 -0.310139 -0.363782 0.370386 -0.31377 -0.322698 -0.300004 -0.314939 -0.651164 -0.206997 -0.249655 -0.816015 -1.05338 -0.423311 -0.815691 -0.226609 5.7 -0.313318 2.73702 1.32206 -0.753043 -0.412162 -0.422868 -0.34775 -0.283044 -0.282042 -0.21301 17.5535 3.97174 0.919084 -0.431528 -0.544155 -0.31415 26.4705 -0.312488 -0.346193 -0.286823 6.79216 -0.748525 -0.98014 -0.492407 -1.03573 -0.254168 -0.340432 -0.600568 -0.603044 -0.6188 -0.211889 -0.20694 -0.280187 -0.286753 0.886182 -0.272744 -0.456996 -0.270212 3.59901 -0.366019 0.720207 -0.881176 -0.436178 11.1911 -0.370755 -0.515897 -0.384355 -0.254783 -0.451551 3.52629 -0.258531 -0.389639 -0.597224 -0.270165 -0.298529 -0.230833 -0.284804 -0.381157 -0.246954 -0.43759 -0.627351 -0.331432 -0.268705 -1.00098 -0.428459 -0.232146 -0.283323 -0.349301 -0.556578 1.48795 -0.343145 -0.471577 -0.360892 -0.531639 -0.405992 -0.282965 -0.718566 -0.618127 -0.477218 -0.255005 -0.575063 -0.354902 -0.403061 -0.372542 -0.252383 -0.452499 -0.290981 -0.322229 -0.581074 -0.295798 -0.327981 -0.781533 -0.474908 -0.282976 -0.291278 -0.30273 -0.208502 -0.2699 -0.462347 -0.32372 -0.317519 -0.339668 -0.390645 -0.607509 -0.270065 -0.293403 -0.514049 -0.264574 -0.537349 -0.685285 -0.196058 -0.455505 -0.693791 -0.496986 2.76995 -0.332677 -0.540408 -0.324506 -0.453971 -0.298455 -0.370312 -0.936154 -0.290015 -0.358557 -0.539365 -0.680306 1.32915 -0.249763 -0.290863 -0.266336 -0.349138 -0.298595 -0.489985 -0.654553 -0.243636 -0.225235 -0.624876 42.3226 -0.356177 -0.596413 -0.361733 -0.884446 -0.569645 -0.295185 -0.436909 -0.396999 -0.611262 1.38576 -0.562195 -0.294242 -0.34308 -0.457571 -0.308678 -0.365413 -0.386632 -0.309651 -0.542444 -0.375537 -0.348132 -0.52674 -0.373906 -0.666107 -0.58927 -0.292179 -0.431696 -0.754322 -0.282973 5.60584 -0.31608 -0.633442 6.90195 -0.348189 -0.613606 -0.310506 -0.294911 
Processing layer: "dense" ("Dense")
Performing Dense operation.

==============================="dense"========================================

0 0 0 0 0.997826 0 0 0 0 0 0 0 0 0 0 0 0 0 11.4914 0 0 0 0 0.0225852 0 0 1.26071 0 2.27901 0 0 0.827259 0 3.77152 0 5.05607 0 0 0 0 0 0 0 0 0 0 6.76198 0 0 0 0 0 0 0 0 0 0 2.60487 3.82132 2.73366 0 0 0 0 0 0 0 0 0.495493 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4.74163 0 2.15494 0.268466 0 2.27789 0 0 0.450926 0 0 0 4.86232 0 0.851171 5.67453 9.52656 0
Skipping unsupported layer: "dropout_3" (Dropout)
Processing layer: "dense_1" ("Dense")
Performing Dense operation.

==============================="dense_1"========================================

0.00353196 0.130265 0.000156349 0.00253797 0.00103511 0.0147453 0.000406629 0.0698989 0.000212201 0.777211 sum = 1.000000
